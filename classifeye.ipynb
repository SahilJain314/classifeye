{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #lin. Alg.\n",
    "import pandas as pd #data processing\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as matimg\n",
    "\n",
    "#importing keras modules\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "#Python Image Library for image processing\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "image_path = 'D:deep/mrlEyes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42952\n"
     ]
    }
   ],
   "source": [
    "def get_im_array(f, size):\n",
    "    im = Image.open(f).resize(size)\n",
    "    return np.array(im)\n",
    "\n",
    "print(len([f for f in os.listdir(image_path+'open')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42952\n",
      "41946\n"
     ]
    }
   ],
   "source": [
    "open_dir = image_path+ 'open/'\n",
    "closed_dir = image_path+ 'closed/'\n",
    "\n",
    "FINAL_SIDELEN = 25\n",
    "FINAL_SHAPE = (FINAL_SIDELEN,FINAL_SIDELEN)\n",
    "\n",
    "open_count = len([f for f in os.listdir(open_dir)])\n",
    "closed_count = len([f for f in os.listdir(closed_dir)])\n",
    "\n",
    "tt_split = .8\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "open_files = random.sample(os.listdir(open_dir), open_count)\n",
    "closed_files = random.sample(os.listdir(closed_dir), closed_count)\n",
    "\n",
    "for f in open_files:\n",
    "    if f.endswith('png'):\n",
    "        if i<=tt_split*open_count:\n",
    "            X_train.append(get_im_array(open_dir+f,FINAL_SHAPE))\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            X_test.append(get_im_array(open_dir+f,FINAL_SHAPE))\n",
    "            y_test.append(1)\n",
    "        i+=1\n",
    "        \n",
    "print(i)\n",
    "    \n",
    "i = 0\n",
    "\n",
    "for f in closed_files:\n",
    "    if f.endswith('png'):\n",
    "        if i<=tt_split*closed_count:\n",
    "            X_train.append(get_im_array(closed_dir+f,FINAL_SHAPE))\n",
    "            y_train.append(0)\n",
    "        else:\n",
    "            X_test.append(get_im_array(closed_dir+f,FINAL_SHAPE))\n",
    "            y_test.append(0)\n",
    "        i+=1\n",
    "        \n",
    "print(i)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "x_train = X_train.reshape(X_train.shape[0], FINAL_SIDELEN, FINAL_SIDELEN, 1)/255.\n",
    "x_test = X_test.reshape(X_test.shape[0], FINAL_SIDELEN, FINAL_SIDELEN, 1)/255.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67919, 25, 25, 1)\n",
      "(16979, 25, 25, 1)\n",
      "(67919,)\n",
      "(16979,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParamters\n",
    "#Max Pooling Sizes\n",
    "m_1 = 2\n",
    "m_4 = 2\n",
    "#Dropout values of the layers\n",
    "d_1 = .4\n",
    "d_2 = .4\n",
    "#kernel sizes\n",
    "k_1 = 3\n",
    "k_2 = 3\n",
    "k_3 = 3\n",
    "k_4 = 3\n",
    "#Convolution layer sizes\n",
    "c_1 = 16\n",
    "c_2 = 8\n",
    "c_3 = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 8)         1160      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4624      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,545\n",
      "Trainable params: 6,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "data_format = 'channels_last'\n",
    "\n",
    "#Building model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(c_1, kernel_size=(k_1, k_1), input_shape=x_train.shape[1:], activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(m_1,m_1)))\n",
    "\n",
    "model.add(Conv2D(c_2, kernel_size=(k_2, k_2), activation='relu', padding='same'))\n",
    "\n",
    "\n",
    "model.add(Conv2D(c_3, kernel_size=(k_4, k_4), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(m_4,m_4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(d_1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "\n",
    "model.add(Dropout(d_2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#Compiling the model\n",
    "model.compile(keras.optimizers.Adam(), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "keras.utils.print_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 67919 samples, validate on 16979 samples\n",
      "Epoch 1/100\n",
      "67919/67919 [==============================] - 4s 62us/step - loss: 0.6816 - acc: 0.5617 - val_loss: 0.6540 - val_acc: 0.7014\n",
      "Epoch 2/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.5956 - acc: 0.7022 - val_loss: 0.4699 - val_acc: 0.8308\n",
      "Epoch 3/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.4401 - acc: 0.8145 - val_loss: 0.3398 - val_acc: 0.8747\n",
      "Epoch 4/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.3642 - acc: 0.8569 - val_loss: 0.2867 - val_acc: 0.8933\n",
      "Epoch 5/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.3151 - acc: 0.8781 - val_loss: 0.2439 - val_acc: 0.9108\n",
      "Epoch 6/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2803 - acc: 0.8928 - val_loss: 0.2136 - val_acc: 0.9226\n",
      "Epoch 7/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2555 - acc: 0.9045 - val_loss: 0.1938 - val_acc: 0.9305\n",
      "Epoch 8/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2376 - acc: 0.9119 - val_loss: 0.1796 - val_acc: 0.9329\n",
      "Epoch 9/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2242 - acc: 0.9176 - val_loss: 0.1708 - val_acc: 0.9424\n",
      "Epoch 10/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2116 - acc: 0.9227 - val_loss: 0.1584 - val_acc: 0.9444\n",
      "Epoch 11/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.2007 - acc: 0.9268 - val_loss: 0.1461 - val_acc: 0.9488\n",
      "Epoch 12/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1928 - acc: 0.9302 - val_loss: 0.1389 - val_acc: 0.9511\n",
      "Epoch 13/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.1827 - acc: 0.9361 - val_loss: 0.1344 - val_acc: 0.9535\n",
      "Epoch 14/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1757 - acc: 0.9380 - val_loss: 0.1240 - val_acc: 0.9558\n",
      "Epoch 15/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1694 - acc: 0.9403 - val_loss: 0.1202 - val_acc: 0.9587\n",
      "Epoch 16/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1607 - acc: 0.9437 - val_loss: 0.1113 - val_acc: 0.9609\n",
      "Epoch 17/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1584 - acc: 0.9448 - val_loss: 0.1099 - val_acc: 0.9608\n",
      "Epoch 18/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1485 - acc: 0.9497 - val_loss: 0.1036 - val_acc: 0.9632\n",
      "Epoch 19/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1458 - acc: 0.9503 - val_loss: 0.1015 - val_acc: 0.9644\n",
      "Epoch 20/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1446 - acc: 0.9501 - val_loss: 0.1007 - val_acc: 0.9651\n",
      "Epoch 21/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1408 - acc: 0.9525 - val_loss: 0.0960 - val_acc: 0.9657\n",
      "Epoch 22/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1356 - acc: 0.9533 - val_loss: 0.0939 - val_acc: 0.9691\n",
      "Epoch 23/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1325 - acc: 0.9550 - val_loss: 0.0907 - val_acc: 0.9680\n",
      "Epoch 24/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1306 - acc: 0.9553 - val_loss: 0.0923 - val_acc: 0.9683\n",
      "Epoch 25/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1273 - acc: 0.9567 - val_loss: 0.0879 - val_acc: 0.9693\n",
      "Epoch 26/100\n",
      "67919/67919 [==============================] - 1s 17us/step - loss: 0.1275 - acc: 0.9576 - val_loss: 0.0896 - val_acc: 0.9681\n",
      "Epoch 27/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1258 - acc: 0.9576 - val_loss: 0.0839 - val_acc: 0.9713\n",
      "Epoch 28/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1206 - acc: 0.9592 - val_loss: 0.0841 - val_acc: 0.9717\n",
      "Epoch 29/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1191 - acc: 0.9596 - val_loss: 0.0817 - val_acc: 0.9726\n",
      "Epoch 30/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1172 - acc: 0.9610 - val_loss: 0.0833 - val_acc: 0.9712\n",
      "Epoch 31/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1195 - acc: 0.9603 - val_loss: 0.0807 - val_acc: 0.9731\n",
      "Epoch 32/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1163 - acc: 0.9618 - val_loss: 0.0848 - val_acc: 0.9699\n",
      "Epoch 33/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1142 - acc: 0.9620 - val_loss: 0.0778 - val_acc: 0.9736\n",
      "Epoch 34/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1099 - acc: 0.9636 - val_loss: 0.0784 - val_acc: 0.9735\n",
      "Epoch 35/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1134 - acc: 0.9626 - val_loss: 0.0761 - val_acc: 0.9746\n",
      "Epoch 36/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1092 - acc: 0.9633 - val_loss: 0.0761 - val_acc: 0.9733\n",
      "Epoch 37/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1086 - acc: 0.9641 - val_loss: 0.0745 - val_acc: 0.9743\n",
      "Epoch 38/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1067 - acc: 0.9648 - val_loss: 0.0742 - val_acc: 0.9742\n",
      "Epoch 39/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.1052 - acc: 0.9649 - val_loss: 0.0731 - val_acc: 0.9740\n",
      "Epoch 40/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.1064 - acc: 0.9648 - val_loss: 0.0753 - val_acc: 0.9744\n",
      "Epoch 41/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.1059 - acc: 0.9646 - val_loss: 0.0729 - val_acc: 0.9764\n",
      "Epoch 42/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1051 - acc: 0.9652 - val_loss: 0.0718 - val_acc: 0.9751\n",
      "Epoch 43/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1045 - acc: 0.9651 - val_loss: 0.0711 - val_acc: 0.9768\n",
      "Epoch 44/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1016 - acc: 0.9667 - val_loss: 0.0699 - val_acc: 0.9763\n",
      "Epoch 45/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.1023 - acc: 0.9659 - val_loss: 0.0695 - val_acc: 0.9769\n",
      "Epoch 46/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0988 - acc: 0.9669 - val_loss: 0.0695 - val_acc: 0.9768\n",
      "Epoch 47/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0995 - acc: 0.9673 - val_loss: 0.0687 - val_acc: 0.9766\n",
      "Epoch 48/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0994 - acc: 0.9674 - val_loss: 0.0683 - val_acc: 0.9773\n",
      "Epoch 49/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0984 - acc: 0.9674 - val_loss: 0.0680 - val_acc: 0.9767\n",
      "Epoch 50/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0981 - acc: 0.9672 - val_loss: 0.0675 - val_acc: 0.9765\n",
      "Epoch 51/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0971 - acc: 0.9677 - val_loss: 0.0654 - val_acc: 0.9774\n",
      "Epoch 52/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0970 - acc: 0.9679 - val_loss: 0.0661 - val_acc: 0.9778\n",
      "Epoch 53/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0938 - acc: 0.9686 - val_loss: 0.0667 - val_acc: 0.9764\n",
      "Epoch 54/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0965 - acc: 0.9689 - val_loss: 0.0655 - val_acc: 0.9771\n",
      "Epoch 55/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0957 - acc: 0.9682 - val_loss: 0.0662 - val_acc: 0.9773\n",
      "Epoch 56/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0975 - acc: 0.9675 - val_loss: 0.0650 - val_acc: 0.9772\n",
      "Epoch 57/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0952 - acc: 0.9689 - val_loss: 0.0644 - val_acc: 0.9779\n",
      "Epoch 58/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0951 - acc: 0.9683 - val_loss: 0.0642 - val_acc: 0.9784\n",
      "Epoch 59/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0937 - acc: 0.9688 - val_loss: 0.0629 - val_acc: 0.9783\n",
      "Epoch 60/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0909 - acc: 0.9702 - val_loss: 0.0629 - val_acc: 0.9783\n",
      "Epoch 61/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0911 - acc: 0.9697 - val_loss: 0.0650 - val_acc: 0.9774\n",
      "Epoch 62/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0923 - acc: 0.9694 - val_loss: 0.0661 - val_acc: 0.9769\n",
      "Epoch 63/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0945 - acc: 0.9694 - val_loss: 0.0622 - val_acc: 0.9789\n",
      "Epoch 64/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0895 - acc: 0.9705 - val_loss: 0.0614 - val_acc: 0.9786\n",
      "Epoch 65/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0897 - acc: 0.9702 - val_loss: 0.0612 - val_acc: 0.9784\n",
      "Epoch 66/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0888 - acc: 0.9706 - val_loss: 0.0607 - val_acc: 0.9787\n",
      "Epoch 67/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0879 - acc: 0.9714 - val_loss: 0.0598 - val_acc: 0.9794\n",
      "Epoch 68/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0879 - acc: 0.9707 - val_loss: 0.0598 - val_acc: 0.9795\n",
      "Epoch 69/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0884 - acc: 0.9709 - val_loss: 0.0603 - val_acc: 0.9793\n",
      "Epoch 70/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0869 - acc: 0.9713 - val_loss: 0.0597 - val_acc: 0.9796\n",
      "Epoch 71/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0873 - acc: 0.9716 - val_loss: 0.0586 - val_acc: 0.9802\n",
      "Epoch 72/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0866 - acc: 0.9715 - val_loss: 0.0594 - val_acc: 0.9801\n",
      "Epoch 73/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0854 - acc: 0.9714 - val_loss: 0.0602 - val_acc: 0.9795\n",
      "Epoch 74/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0853 - acc: 0.9721 - val_loss: 0.0583 - val_acc: 0.9796\n",
      "Epoch 75/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0838 - acc: 0.9717 - val_loss: 0.0570 - val_acc: 0.9801\n",
      "Epoch 76/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0850 - acc: 0.9720 - val_loss: 0.0574 - val_acc: 0.9805\n",
      "Epoch 77/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0846 - acc: 0.9719 - val_loss: 0.0580 - val_acc: 0.9800\n",
      "Epoch 78/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0850 - acc: 0.9719 - val_loss: 0.0650 - val_acc: 0.9772\n",
      "Epoch 79/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.0871 - acc: 0.9712 - val_loss: 0.0578 - val_acc: 0.9800\n",
      "Epoch 80/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.0827 - acc: 0.9725 - val_loss: 0.0577 - val_acc: 0.9794\n",
      "Epoch 81/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0845 - acc: 0.9722 - val_loss: 0.0573 - val_acc: 0.9803\n",
      "Epoch 82/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0816 - acc: 0.9728 - val_loss: 0.0566 - val_acc: 0.9799\n",
      "Epoch 83/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0829 - acc: 0.9723 - val_loss: 0.0558 - val_acc: 0.9806\n",
      "Epoch 84/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0826 - acc: 0.9723 - val_loss: 0.0562 - val_acc: 0.9810\n",
      "Epoch 85/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0831 - acc: 0.9724 - val_loss: 0.0559 - val_acc: 0.9804\n",
      "Epoch 86/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0823 - acc: 0.9727 - val_loss: 0.0552 - val_acc: 0.9800\n",
      "Epoch 87/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0821 - acc: 0.9729 - val_loss: 0.0559 - val_acc: 0.9802\n",
      "Epoch 88/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0807 - acc: 0.9732 - val_loss: 0.0566 - val_acc: 0.9795\n",
      "Epoch 89/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0812 - acc: 0.9727 - val_loss: 0.0548 - val_acc: 0.9807\n",
      "Epoch 90/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0823 - acc: 0.9724 - val_loss: 0.0561 - val_acc: 0.9800\n",
      "Epoch 91/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0811 - acc: 0.9730 - val_loss: 0.0543 - val_acc: 0.9811\n",
      "Epoch 92/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0814 - acc: 0.9727 - val_loss: 0.0549 - val_acc: 0.9811\n",
      "Epoch 93/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0799 - acc: 0.9736 - val_loss: 0.0584 - val_acc: 0.9797\n",
      "Epoch 94/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0819 - acc: 0.9729 - val_loss: 0.0557 - val_acc: 0.9806\n",
      "Epoch 95/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0792 - acc: 0.9737 - val_loss: 0.0541 - val_acc: 0.9811\n",
      "Epoch 96/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0799 - acc: 0.9739 - val_loss: 0.0580 - val_acc: 0.9790\n",
      "Epoch 97/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0810 - acc: 0.9727 - val_loss: 0.0555 - val_acc: 0.9809\n",
      "Epoch 98/100\n",
      "67919/67919 [==============================] - 1s 19us/step - loss: 0.0792 - acc: 0.9735 - val_loss: 0.0551 - val_acc: 0.9799\n",
      "Epoch 99/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0796 - acc: 0.9739 - val_loss: 0.0548 - val_acc: 0.9804\n",
      "Epoch 100/100\n",
      "67919/67919 [==============================] - 1s 18us/step - loss: 0.0786 - acc: 0.9738 - val_loss: 0.0531 - val_acc: 0.9814\n"
     ]
    }
   ],
   "source": [
    "#Number of epochs to train with\n",
    "epoch_num = 100\n",
    "\n",
    "model_log = model.fit(x_train, y_train, epochs=epoch_num, batch_size=2000, verbose=1, validation_data=(x_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_log.history['val_acc'])\n",
    "plt.plot(model_log.history['acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a Keras model as an .h5 file\n",
    "model.save('classifeye.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "[[0.9953916]]\n",
      "\n",
      "Correct: \n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Shows the image and prediction for the 'view_num' element of the test set.\n",
    "view_num = 4\n",
    "\n",
    "\n",
    "print('Prediction: ')\n",
    "print(model.predict(x_test[view_num:view_num+1]))\n",
    "print()\n",
    "print('Correct: ')\n",
    "print(y_test[view_num])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\sahil\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('cassifeye.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
